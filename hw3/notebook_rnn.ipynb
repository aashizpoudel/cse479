{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6defa85-27c4-4b04-887c-42446c3146ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "import tensorflow_datasets as tfds \n",
    "DATA_DIR = \"./tensorflow-datasets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ae7732-c72c-4328-a5da-1219437a6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 08:21:59.347840: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 08:22:02.141529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30972 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "for_vocabulary = tfds.load(\"imdb_reviews\", split=\"train\", with_info=False, as_supervised=True, data_dir=DATA_DIR)\n",
    "train_ds,val_ds = tfds.load('imdb_reviews', split=[\"train[:70%]\",\"train[70%:]\"], with_info=False,\n",
    "                          as_supervised=True,data_dir=DATA_DIR)\n",
    "\n",
    "# train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "# train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed801193-c0f4-4fb4-8a94-f32c5c870873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500, 25000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds), len(for_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8931eba-c988-4764-81ac-e33195481a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE=64\n",
    "# BUFFER_SIZE=10000\n",
    "# train_batched = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "# val_batched = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d79f61-4438-4484-b372-733e2804ecd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244a7936-2cbb-4a2a-8008-d007a4e92347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 08:22:02.615277: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 08:22:02.831114: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_ds.take(1):\n",
    "    print(example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076981b4-01c9-4658-b59b-da1bd92008e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length = for_vocabulary.map(lambda text,label: len(tf.strings.split(text,\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b332dea4-6592-4cf4-9e83-33a185c759c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')\n",
    "\n",
    "def get_text_vectorizer(dataset, vocab_size=1000, sequence_length=500):\n",
    "    vectorizer = tf.keras.layers.TextVectorization(standardize=custom_standardization, max_tokens=vocab_size,output_mode='int',output_sequence_length=sequence_length)\n",
    "    vectorizer.adapt(dataset.map(lambda text,label: text))\n",
    "    return vectorizer \n",
    "\n",
    "def train_model(model, train_ds, val_ds, loss_fn, batch_size=64, optimizer=tf.keras.optimizers.Adam(), callbacks=None, epochs=50):\n",
    "    train_batched = train_ds.shuffle(1000).batch(batch_size)\n",
    "    val_batched = val_ds.shuffle(1000).batch(batch_size)\n",
    "    model.compile(loss=loss_fn, optimizer=optimizer,\n",
    "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.5)])\n",
    "    history = model.fit(train_batched, epochs=epochs, validation_data=val_batched,callbacks=callbacks)\n",
    "    return history\n",
    "\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt \n",
    "def evaluate_model(model, val_ds, result_path=None):\n",
    "    val_batched = val_ds.batch(64)\n",
    "    predictions = (tf.nn.sigmoid(model.predict(val_batched)) > 0.5).numpy()\n",
    "    truth = np.concatenate([label.numpy() for _,label in val_batched],axis=0)\n",
    "    accuracy = accuracy_score(truth, predictions)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_pred=predictions, y_true=truth,normalize=\"true\")\n",
    "    if result_path:\n",
    "        plt.savefig(result_path.joinpath('confusion_matrix.jpg'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    return accuracy \n",
    "    \n",
    "def plot_training_graphs(history, result_path=None):\n",
    "    plt.plot(history.history['loss'],label=\"training\")\n",
    "    plt.plot(history.history['val_loss'],label=\"validation\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    if result_path:\n",
    "        plt.savefig(result_path.joinpath('training_history.jpg'))\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778db6c0-5c41-4ece-9973-0246de0c2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add attention layer to the deep learning network\n",
    "import keras.backend as K\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    " \n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(Attention, self).build(input_shape)\n",
    " \n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context =K.sum(context, axis=1)\n",
    "        return context\n",
    "    \n",
    "    \n",
    "def get_bidirectional_lstm_attention(vectorizer,kernel_regularizer=None, use_dropout=False):\n",
    "    input = tf.keras.layers.Input(shape=[None],dtype=tf.string)\n",
    "    vocab_len = len(vectorizer.get_vocabulary())\n",
    "    x = vectorizer(input)\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_len, output_dim=64, mask_zero=True,name=\"embedding\")(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True,kernel_regularizer=kernel_regularizer), name=\"bi_lstm_0\")(x)\n",
    "    # x, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True, return_state=True), name=\"bi_lstm_0\")(x)\n",
    "    # x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True,kernel_regularizer=kernel_regularizer), name=\"bi_lstm_1\")(x)\n",
    "    x = Attention()(x)\n",
    "    # x = tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=kernel_regularizer )(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer)(x)\n",
    "    if use_dropout:\n",
    "        x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "    return tf.keras.Model(inputs=input,outputs=x)\n",
    "\n",
    "\n",
    "def get_bidirectional_gru_attention(vectorizer,kernel_regularizer=None, use_dropout=False):\n",
    "    input = tf.keras.layers.Input(shape=[None],dtype=tf.string)\n",
    "    vocab_len = len(vectorizer.get_vocabulary())\n",
    "    x = vectorizer(input)\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_len, output_dim=64, mask_zero=True,name=\"embedding\")(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True,kernel_regularizer=kernel_regularizer), name=\"bi_gru_0\")(x)\n",
    "    # x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True,kernel_regularizer=kernel_regularizer), name=\"bi_lstm_0\")(x)\n",
    "    # x, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True, return_state=True), name=\"bi_lstm_0\")(x)\n",
    "    \n",
    "    x = Attention()(x)\n",
    "    \n",
    "    # x = tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=kernel_regularizer )(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer)(x)\n",
    "    if use_dropout:\n",
    "        x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "    return tf.keras.Model(inputs=input,outputs=x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630fddde-ef03-4a79-aa44-d2a11105a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = get_text_vectorizer(for_vocabulary,vocab_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319eb6da-798a-4a79-a268-34e3dee870c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer loaded\n",
      "Working on 32_0.01_True\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 500, 64)           1920000   \n",
      "_________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)     (None, 500, 128)          49920     \n",
      "_________________________________________________________________\n",
      "attention_4 (Attention)      (None, 128)               628       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,978,869\n",
      "Trainable params: 1,978,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "547/547 [==============================] - 24s 37ms/step - loss: 0.7211 - binary_accuracy: 0.5007 - val_loss: 0.6931 - val_binary_accuracy: 0.4984\n",
      "Epoch 2/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6934 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "Epoch 3/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6934 - binary_accuracy: 0.5007 - val_loss: 0.6934 - val_binary_accuracy: 0.4984\n",
      "Epoch 4/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6934 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "Epoch 5/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6935 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "Epoch 6/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6936 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "Epoch 7/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6935 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "Epoch 8/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6934 - binary_accuracy: 0.5007 - val_loss: 0.6931 - val_binary_accuracy: 0.4984\n",
      "Epoch 9/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6935 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "Epoch 10/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6934 - binary_accuracy: 0.5007 - val_loss: 0.6933 - val_binary_accuracy: 0.4984\n",
      "Epoch 11/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.6936 - binary_accuracy: 0.5007 - val_loss: 0.6932 - val_binary_accuracy: 0.4984\n",
      "For 32_0.01_True accuracy 0.5016 early_stopping 0.6931430101394653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru/32_0.01_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru/32_0.01_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.01_False\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 500, 64)           1920000   \n",
      "_________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)     (None, 500, 128)          49920     \n",
      "_________________________________________________________________\n",
      "attention_5 (Attention)      (None, 128)               628       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,978,869\n",
      "Trainable params: 1,978,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "547/547 [==============================] - 24s 37ms/step - loss: 0.3556 - binary_accuracy: 0.8362 - val_loss: 0.2465 - val_binary_accuracy: 0.8949\n",
      "Epoch 2/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.1182 - binary_accuracy: 0.9548 - val_loss: 0.3303 - val_binary_accuracy: 0.8739\n",
      "Epoch 3/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.0493 - binary_accuracy: 0.9820 - val_loss: 0.3915 - val_binary_accuracy: 0.8788\n",
      "Epoch 4/200\n",
      "547/547 [==============================] - 19s 34ms/step - loss: 0.0308 - binary_accuracy: 0.9894 - val_loss: 0.4419 - val_binary_accuracy: 0.8777\n",
      "Epoch 5/200\n",
      "241/547 [============>.................] - ETA: 8s - loss: 0.0298 - binary_accuracy: 0.9890"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m early_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_ds,result_path\u001b[38;5;241m=\u001b[39mresult_path)\n\u001b[1;32m     25\u001b[0m plot_training_graphs(history, result_path)\n",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_ds, val_ds, loss_fn, batch_size, optimizer, callbacks, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m val_batched \u001b[38;5;241m=\u001b[39m val_ds\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss_fn, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     20\u001b[0m           metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)])\n\u001b[0;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#experiment 1\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "# vectorizer = get_text_vectorizer(for_vocabulary)\n",
    "model_fn = get_bidirectional_gru_attention\n",
    "result_dir = Path(\"./results_gru\")\n",
    "exp_results = []\n",
    "print(\"vectorizer loaded\")\n",
    "for batch_size in [32,64]:\n",
    "    for learning_rate in [0.01,0.001]:\n",
    "        for regularizer in [True, False]:\n",
    "            s_result = {'batch_size':batch_size,'learning_rate':learning_rate,'regularizer':regularizer}\n",
    "            folder_name = f\"{batch_size}_{learning_rate}_{regularizer}\"\n",
    "            result_path = result_dir.joinpath(folder_name)\n",
    "            result_path.mkdir(parents=True,exist_ok=True)\n",
    "            print(\"Working on\",folder_name)\n",
    "            reg = tf.keras.regularizers.l2() if regularizer else None\n",
    "            model = model_fn(vectorizer=vectorizer,kernel_regularizer=reg,use_dropout=regularizer)\n",
    "            print(model.summary())\n",
    "            early_callback = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "            history = train_model(model, train_ds, val_ds, loss_fn, batch_size=batch_size, optimizer=optimizer, callbacks=[early_callback],epochs=200)\n",
    "            accuracy = evaluate_model(model, val_ds,result_path=result_path)\n",
    "            plot_training_graphs(history, result_path)\n",
    "            print(\"For\",folder_name,\"accuracy\",accuracy,\"early_stopping\", early_callback.best)\n",
    "            s_result['accuracy'] = accuracy\n",
    "            s_result['logs'] = history.history \n",
    "            model.save_weights(result_path.joinpath(\"best_weights.hd5\"))\n",
    "            model.save(result_path.joinpath(\"best_model.hd5\"))\n",
    "            # print(\"Accuracy on validation\", accuracy)\n",
    "            # break\n",
    "            s_result['model'] = result_path.joinpath(\"best_model.hd5\")\n",
    "            exp_results.append(s_result)\n",
    "            del model\n",
    "pd.DataFrame(exp_results).to_csv(\"./results_gru/exp_results.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0eeaf5-25b1-421f-8dea-515b148fe9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment 1\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "# vectorizer = get_text_vectorizer(for_vocabulary)\n",
    "model_fn = get_bidirectional_lstm_attention\n",
    "result_dir = Path(\"./results_lstm\")\n",
    "exp_results = []\n",
    "print(\"vectorizer loaded\")\n",
    "for batch_size in [32,64]:\n",
    "    for learning_rate in [0.01,0.001]:\n",
    "        for regularizer in [True, False]:\n",
    "            s_result = {'batch_size':batch_size,'learning_rate':learning_rate,'regularizer':regularizer}\n",
    "            folder_name = f\"{batch_size}_{learning_rate}_{regularizer}\"\n",
    "            result_path = result_dir.joinpath(folder_name)\n",
    "            result_path.mkdir(parents=True,exist_ok=True)\n",
    "            print(\"Working on\",folder_name)\n",
    "            reg = tf.keras.regularizers.l2() if regularizer else None\n",
    "            model = model_fn(vectorizer=vectorizer,kernel_regularizer=reg,use_dropout=regularizer)\n",
    "            print(model.summary())\n",
    "            early_callback = tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "            history = train_model(model, train_ds, val_ds, loss_fn, batch_size=batch_size, optimizer=optimizer, callbacks=[early_callback],epochs=200)\n",
    "            accuracy = evaluate_model(model, val_ds,result_path=result_path)\n",
    "            plot_training_graphs(history, result_path)\n",
    "            print(\"For\",folder_name,\"accuracy\",accuracy,\"early_stopping\", early_callback.best)\n",
    "            s_result['accuracy'] = accuracy\n",
    "            s_result['logs'] = history.history \n",
    "            model.save_weights(result_path.joinpath(\"best_weights.hd5\"))\n",
    "            model.save(result_path.joinpath(\"best_model.hd5\"))\n",
    "            # print(\"Accuracy on validation\", accuracy)\n",
    "            s_result['model'] = result_path.joinpath(\"best_model.hd5\")\n",
    "\n",
    "            # break\n",
    "            exp_results.append(s_result)\n",
    "            del model\n",
    "pd.DataFrame(exp_results).to_csv(\"./results_lstm/exp_results.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60b9def-a3b9-44ef-96af-39bf7adec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f31234e-2ce0-4777-978d-c9eb7dc5fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import main\n",
    "import model\n",
    "import util\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3542392d-7ce8-4ea3-8e8c-ced6dd7bf6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 15:42:51.264616: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 15:42:54.137185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30972 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = util.get_train_val_ds()\n",
    "vocab = util.get_for_vocab_ds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60048a7-7383-41b4-8a9f-03346633c19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds),len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5668d514-dad0-421d-ad20-bd239cd132d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 15:42:54.595707: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = util.get_text_vectorizer(vocab, vocab_size=30000,sequence_length=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c97838-a60f-41d5-b9b9-2e6fcbe71e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.01_True\n",
      "<keras.regularizers.L1L2 object at 0x14c4e1686520>\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[9][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            129         dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 36s 69ms/step - loss: 0.6610 - binary_accuracy: 0.7277 - val_loss: 0.4449 - val_binary_accuracy: 0.8499\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.4824 - binary_accuracy: 0.8676 - val_loss: 0.4271 - val_binary_accuracy: 0.8443\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.3255 - binary_accuracy: 0.9067 - val_loss: 0.4658 - val_binary_accuracy: 0.8563\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.3053 - binary_accuracy: 0.9225 - val_loss: 0.5333 - val_binary_accuracy: 0.8488\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2754 - binary_accuracy: 0.9321 - val_loss: 0.5069 - val_binary_accuracy: 0.8441\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2297 - binary_accuracy: 0.9469 - val_loss: 0.5649 - val_binary_accuracy: 0.8458\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2116 - binary_accuracy: 0.9598 - val_loss: 0.6429 - val_binary_accuracy: 0.8378\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2504 - binary_accuracy: 0.9629 - val_loss: 0.5657 - val_binary_accuracy: 0.8405\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 1.3166 - binary_accuracy: 0.9591 - val_loss: 21.6933 - val_binary_accuracy: 0.8004\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 21.7869 - binary_accuracy: 0.9426 - val_loss: 22.0871 - val_binary_accuracy: 0.7990\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 21.5781 - binary_accuracy: 0.9603 - val_loss: 22.0029 - val_binary_accuracy: 0.8260\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 21.4815 - binary_accuracy: 0.9746 - val_loss: 22.0925 - val_binary_accuracy: 0.8279\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 21.4143 - binary_accuracy: 0.9784 - val_loss: 21.9974 - val_binary_accuracy: 0.8264\n",
      "For 32_0.01_True accuracy 0.8588 early_stopping 0.8562999963760376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses, lstm_cell_29_layer_call_fn, lstm_cell_29_layer_call_and_return_conditional_losses, lstm_cell_28_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.01_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.01_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.01_False\n",
      "None\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[10][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_10 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            129         bi_lstm_0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 36s 66ms/step - loss: 0.3852 - binary_accuracy: 0.8213 - val_loss: 0.3484 - val_binary_accuracy: 0.8425\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2748 - binary_accuracy: 0.8889 - val_loss: 0.4055 - val_binary_accuracy: 0.8287\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2487 - binary_accuracy: 0.8977 - val_loss: 0.4360 - val_binary_accuracy: 0.8299\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1522 - binary_accuracy: 0.9425 - val_loss: 0.4724 - val_binary_accuracy: 0.8369\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1113 - binary_accuracy: 0.9587 - val_loss: 0.5869 - val_binary_accuracy: 0.8270\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0879 - binary_accuracy: 0.9673 - val_loss: 0.5458 - val_binary_accuracy: 0.8218\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0656 - binary_accuracy: 0.9759 - val_loss: 0.6079 - val_binary_accuracy: 0.8202\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0670 - binary_accuracy: 0.9755 - val_loss: 0.6321 - val_binary_accuracy: 0.8228\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0492 - binary_accuracy: 0.9837 - val_loss: 0.7187 - val_binary_accuracy: 0.8048\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0483 - binary_accuracy: 0.9832 - val_loss: 0.8050 - val_binary_accuracy: 0.8107\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0424 - binary_accuracy: 0.9850 - val_loss: 0.7835 - val_binary_accuracy: 0.8035\n",
      "For 32_0.01_False accuracy 0.8514 early_stopping 0.8424999713897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn, lstm_cell_32_layer_call_and_return_conditional_losses, lstm_cell_31_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.01_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.01_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.001_True\n",
      "<keras.regularizers.L1L2 object at 0x14cce92d5970>\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[11][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_11 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128)          0           bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            129         dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 35s 66ms/step - loss: 1.1265 - binary_accuracy: 0.5184 - val_loss: 0.6959 - val_binary_accuracy: 0.4990\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5757 - binary_accuracy: 0.6755 - val_loss: 0.8242 - val_binary_accuracy: 0.6808\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5138 - binary_accuracy: 0.7133 - val_loss: 0.3761 - val_binary_accuracy: 0.8789\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.4991 - binary_accuracy: 0.8027 - val_loss: 0.4192 - val_binary_accuracy: 0.8837\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2844 - binary_accuracy: 0.9335 - val_loss: 0.4048 - val_binary_accuracy: 0.8868\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3383 - binary_accuracy: 0.9067 - val_loss: 0.4717 - val_binary_accuracy: 0.8688\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2062 - binary_accuracy: 0.9598 - val_loss: 0.3773 - val_binary_accuracy: 0.8820\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.1331 - binary_accuracy: 0.9761 - val_loss: 0.3741 - val_binary_accuracy: 0.8792\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0908 - binary_accuracy: 0.9843 - val_loss: 0.3891 - val_binary_accuracy: 0.8753\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.0646 - binary_accuracy: 0.9899 - val_loss: 0.4475 - val_binary_accuracy: 0.8818\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0472 - binary_accuracy: 0.9945 - val_loss: 0.4518 - val_binary_accuracy: 0.8796\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0431 - binary_accuracy: 0.9944 - val_loss: 0.4809 - val_binary_accuracy: 0.8736\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.0326 - binary_accuracy: 0.9966 - val_loss: 0.5226 - val_binary_accuracy: 0.8798\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0370 - binary_accuracy: 0.9951 - val_loss: 0.4945 - val_binary_accuracy: 0.8783\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0291 - binary_accuracy: 0.9971 - val_loss: 0.5236 - val_binary_accuracy: 0.8749\n",
      "For 32_0.001_True accuracy 0.8889 early_stopping 0.8867999911308289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_34_layer_call_fn, lstm_cell_34_layer_call_and_return_conditional_losses, lstm_cell_35_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses, lstm_cell_34_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.001_False\n",
      "None\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[12][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            129         bi_lstm_0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 35s 66ms/step - loss: 0.4379 - binary_accuracy: 0.7817 - val_loss: 0.3354 - val_binary_accuracy: 0.8612\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.2071 - binary_accuracy: 0.9212 - val_loss: 0.3494 - val_binary_accuracy: 0.8681\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.1114 - binary_accuracy: 0.9637 - val_loss: 0.4196 - val_binary_accuracy: 0.8714\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.0841 - binary_accuracy: 0.9757 - val_loss: 0.4662 - val_binary_accuracy: 0.8661\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1012 - binary_accuracy: 0.9582 - val_loss: 0.4636 - val_binary_accuracy: 0.8679\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.0142 - binary_accuracy: 0.9967 - val_loss: 0.8078 - val_binary_accuracy: 0.8687\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0171 - binary_accuracy: 0.9946 - val_loss: 0.6570 - val_binary_accuracy: 0.8673\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0073 - binary_accuracy: 0.9976 - val_loss: 0.7786 - val_binary_accuracy: 0.8686\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0017 - binary_accuracy: 0.9994 - val_loss: 0.9363 - val_binary_accuracy: 0.8680\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0125 - binary_accuracy: 0.9964 - val_loss: 0.8619 - val_binary_accuracy: 0.8666\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0103 - binary_accuracy: 0.9974 - val_loss: 0.9428 - val_binary_accuracy: 0.8624\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0360 - binary_accuracy: 0.9899 - val_loss: 0.5489 - val_binary_accuracy: 0.8587\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0136 - binary_accuracy: 0.9957 - val_loss: 0.8123 - val_binary_accuracy: 0.8616\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.0026 - binary_accuracy: 0.9993 - val_loss: 0.8833 - val_binary_accuracy: 0.8685\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 2.2553e-04 - binary_accuracy: 0.9999 - val_loss: 1.0041 - val_binary_accuracy: 0.8700\n",
      "For 32_0.001_False accuracy 0.8718 early_stopping 0.8726000189781189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_37_layer_call_fn, lstm_cell_37_layer_call_and_return_conditional_losses, lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_37_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.0001_True\n",
      "<keras.regularizers.L1L2 object at 0x14cce8086190>\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[13][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128)          0           bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            129         dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 35s 67ms/step - loss: 3.4353 - binary_accuracy: 0.6525 - val_loss: 2.2483 - val_binary_accuracy: 0.8131\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.7751 - binary_accuracy: 0.6541 - val_loss: 1.1789 - val_binary_accuracy: 0.8372\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.8970 - binary_accuracy: 0.8585 - val_loss: 0.7897 - val_binary_accuracy: 0.8157\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.7034 - binary_accuracy: 0.8223 - val_loss: 0.6809 - val_binary_accuracy: 0.8531\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5793 - binary_accuracy: 0.8916 - val_loss: 0.6624 - val_binary_accuracy: 0.8562\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5875 - binary_accuracy: 0.8744 - val_loss: 0.6334 - val_binary_accuracy: 0.8577\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5057 - binary_accuracy: 0.9095 - val_loss: 0.6133 - val_binary_accuracy: 0.8607\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.6124 - binary_accuracy: 0.8507 - val_loss: 0.6441 - val_binary_accuracy: 0.8226\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.4828 - binary_accuracy: 0.9095 - val_loss: 0.5888 - val_binary_accuracy: 0.8642\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5041 - binary_accuracy: 0.8960 - val_loss: 0.5785 - val_binary_accuracy: 0.8623\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.6716 - binary_accuracy: 0.7249 - val_loss: 0.8436 - val_binary_accuracy: 0.4990\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.8119 - binary_accuracy: 0.5007 - val_loss: 0.7808 - val_binary_accuracy: 0.4990\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.6086 - binary_accuracy: 0.7604 - val_loss: 0.6656 - val_binary_accuracy: 0.7529\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5247 - binary_accuracy: 0.8703 - val_loss: 0.5510 - val_binary_accuracy: 0.8616\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5801 - binary_accuracy: 0.8155 - val_loss: 0.5897 - val_binary_accuracy: 0.8223\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5441 - binary_accuracy: 0.8595 - val_loss: 0.8220 - val_binary_accuracy: 0.5710\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5392 - binary_accuracy: 0.8235 - val_loss: 0.5435 - val_binary_accuracy: 0.8627\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3905 - binary_accuracy: 0.9310 - val_loss: 0.5442 - val_binary_accuracy: 0.8675\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3638 - binary_accuracy: 0.9389 - val_loss: 0.5483 - val_binary_accuracy: 0.8676\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.3625 - binary_accuracy: 0.9365 - val_loss: 0.5392 - val_binary_accuracy: 0.8687\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3427 - binary_accuracy: 0.9411 - val_loss: 0.5367 - val_binary_accuracy: 0.8688\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3681 - binary_accuracy: 0.9211 - val_loss: 0.5392 - val_binary_accuracy: 0.8647\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5842 - binary_accuracy: 0.7687 - val_loss: 0.5469 - val_binary_accuracy: 0.8458\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.5777 - binary_accuracy: 0.7167 - val_loss: 0.7366 - val_binary_accuracy: 0.5101\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.3669 - binary_accuracy: 0.8854 - val_loss: 0.5015 - val_binary_accuracy: 0.8689\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3190 - binary_accuracy: 0.9207 - val_loss: 0.5304 - val_binary_accuracy: 0.7563\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.4957 - binary_accuracy: 0.7495 - val_loss: 0.6304 - val_binary_accuracy: 0.7046\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.4198 - binary_accuracy: 0.8704 - val_loss: 0.4724 - val_binary_accuracy: 0.8662\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2570 - binary_accuracy: 0.9545 - val_loss: 0.5366 - val_binary_accuracy: 0.8754\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2446 - binary_accuracy: 0.9545 - val_loss: 0.4353 - val_binary_accuracy: 0.8435\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.3386 - binary_accuracy: 0.9225 - val_loss: 0.5257 - val_binary_accuracy: 0.8748\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2310 - binary_accuracy: 0.9639 - val_loss: 0.5087 - val_binary_accuracy: 0.8711\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2152 - binary_accuracy: 0.9669 - val_loss: 0.5181 - val_binary_accuracy: 0.8716\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2114 - binary_accuracy: 0.9663 - val_loss: 0.5368 - val_binary_accuracy: 0.8754\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2117 - binary_accuracy: 0.9651 - val_loss: 0.5189 - val_binary_accuracy: 0.8604\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2063 - binary_accuracy: 0.9643 - val_loss: 0.5168 - val_binary_accuracy: 0.8731\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2129 - binary_accuracy: 0.9598 - val_loss: 0.5174 - val_binary_accuracy: 0.8669\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.2379 - binary_accuracy: 0.9506 - val_loss: 0.4963 - val_binary_accuracy: 0.8741\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.4052 - binary_accuracy: 0.8411 - val_loss: 0.4927 - val_binary_accuracy: 0.8672\n",
      "For 32_0.0001_True accuracy 0.8759 early_stopping 0.8754000067710876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.0001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.0001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.0001_False\n",
      "None\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[14][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_14 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            129         bi_lstm_0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 35s 66ms/step - loss: 0.5558 - binary_accuracy: 0.6847 - val_loss: 0.4227 - val_binary_accuracy: 0.8350\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.3905 - binary_accuracy: 0.8375 - val_loss: 0.4075 - val_binary_accuracy: 0.8436\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3807 - binary_accuracy: 0.8435 - val_loss: 0.5001 - val_binary_accuracy: 0.8179\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5684 - binary_accuracy: 0.6988 - val_loss: 0.5654 - val_binary_accuracy: 0.7577\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.3490 - binary_accuracy: 0.8465 - val_loss: 0.3588 - val_binary_accuracy: 0.8356\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2349 - binary_accuracy: 0.8960 - val_loss: 0.5391 - val_binary_accuracy: 0.6987\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.4522 - binary_accuracy: 0.6191 - val_loss: 0.5698 - val_binary_accuracy: 0.5103\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.3952 - binary_accuracy: 0.5929 - val_loss: 0.3504 - val_binary_accuracy: 0.8152\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.1901 - binary_accuracy: 0.9209 - val_loss: 0.3460 - val_binary_accuracy: 0.8534\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.2215 - binary_accuracy: 0.9233 - val_loss: 0.3699 - val_binary_accuracy: 0.8715\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.2252 - binary_accuracy: 0.9355 - val_loss: 0.3795 - val_binary_accuracy: 0.8743\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1815 - binary_accuracy: 0.9539 - val_loss: 0.4156 - val_binary_accuracy: 0.8742\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1919 - binary_accuracy: 0.9493 - val_loss: 0.4126 - val_binary_accuracy: 0.8724\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1819 - binary_accuracy: 0.9517 - val_loss: 0.5489 - val_binary_accuracy: 0.7780\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.1585 - binary_accuracy: 0.9593 - val_loss: 0.4089 - val_binary_accuracy: 0.8763\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1733 - binary_accuracy: 0.9509 - val_loss: 0.3992 - val_binary_accuracy: 0.8696\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1524 - binary_accuracy: 0.9544 - val_loss: 0.3935 - val_binary_accuracy: 0.8692\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1551 - binary_accuracy: 0.9277 - val_loss: 0.4826 - val_binary_accuracy: 0.7925\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1397 - binary_accuracy: 0.9613 - val_loss: 0.4497 - val_binary_accuracy: 0.8692\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1158 - binary_accuracy: 0.9700 - val_loss: 0.4453 - val_binary_accuracy: 0.8778\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1266 - binary_accuracy: 0.9668 - val_loss: 0.4018 - val_binary_accuracy: 0.8752\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1445 - binary_accuracy: 0.9606 - val_loss: 0.4458 - val_binary_accuracy: 0.8723\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1043 - binary_accuracy: 0.9711 - val_loss: 0.4323 - val_binary_accuracy: 0.8768\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1387 - binary_accuracy: 0.9535 - val_loss: 0.3840 - val_binary_accuracy: 0.8239\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1175 - binary_accuracy: 0.9653 - val_loss: 0.4247 - val_binary_accuracy: 0.8660\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0875 - binary_accuracy: 0.9697 - val_loss: 0.4163 - val_binary_accuracy: 0.8675\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0896 - binary_accuracy: 0.9711 - val_loss: 0.4417 - val_binary_accuracy: 0.8837\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0631 - binary_accuracy: 0.9827 - val_loss: 0.3944 - val_binary_accuracy: 0.8568\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0880 - binary_accuracy: 0.9766 - val_loss: 0.4942 - val_binary_accuracy: 0.8775\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0546 - binary_accuracy: 0.9879 - val_loss: 0.4973 - val_binary_accuracy: 0.8770\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0667 - binary_accuracy: 0.9801 - val_loss: 0.4768 - val_binary_accuracy: 0.8783\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0414 - binary_accuracy: 0.9894 - val_loss: 0.5143 - val_binary_accuracy: 0.8781\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0399 - binary_accuracy: 0.9917 - val_loss: 0.4404 - val_binary_accuracy: 0.8775\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0314 - binary_accuracy: 0.9939 - val_loss: 0.8021 - val_binary_accuracy: 0.7882\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0555 - binary_accuracy: 0.9873 - val_loss: 0.5381 - val_binary_accuracy: 0.8773\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0446 - binary_accuracy: 0.9894 - val_loss: 0.5786 - val_binary_accuracy: 0.8760\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.0381 - binary_accuracy: 0.9912 - val_loss: 0.5643 - val_binary_accuracy: 0.8744\n",
      "For 32_0.0001_False accuracy 0.8835 early_stopping 0.8837000131607056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_44_layer_call_fn, lstm_cell_44_layer_call_and_return_conditional_losses, lstm_cell_43_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.0001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/32_0.0001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 64_0.01_True\n",
      "<keras.regularizers.L1L2 object at 0x14ccddb79a60>\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[15][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_15 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128)          0           bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1)            129         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "235/235 [==============================] - 26s 94ms/step - loss: 0.7503 - binary_accuracy: 0.7021 - val_loss: 0.5510 - val_binary_accuracy: 0.7335\n",
      "Epoch 2/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.4615 - binary_accuracy: 0.8601 - val_loss: 0.5567 - val_binary_accuracy: 0.8355\n",
      "Epoch 3/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.3960 - binary_accuracy: 0.8898 - val_loss: 0.5236 - val_binary_accuracy: 0.7955\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.3760 - binary_accuracy: 0.9081 - val_loss: 0.6150 - val_binary_accuracy: 0.8092\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.2728 - binary_accuracy: 0.9341 - val_loss: 0.5152 - val_binary_accuracy: 0.8466\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1921 - binary_accuracy: 0.9573 - val_loss: 0.5502 - val_binary_accuracy: 0.8466\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1624 - binary_accuracy: 0.9701 - val_loss: 0.6451 - val_binary_accuracy: 0.7820\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1685 - binary_accuracy: 0.9688 - val_loss: 0.5438 - val_binary_accuracy: 0.8354\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1407 - binary_accuracy: 0.9802 - val_loss: 0.6263 - val_binary_accuracy: 0.8443\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1445 - binary_accuracy: 0.9773 - val_loss: 0.6582 - val_binary_accuracy: 0.8361\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1593 - binary_accuracy: 0.9735 - val_loss: 0.7953 - val_binary_accuracy: 0.8183\n",
      "Epoch 12/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1457 - binary_accuracy: 0.9785 - val_loss: 0.6914 - val_binary_accuracy: 0.8327\n",
      "Epoch 13/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1486 - binary_accuracy: 0.9836 - val_loss: 0.7038 - val_binary_accuracy: 0.8227\n",
      "Epoch 14/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1305 - binary_accuracy: 0.9822 - val_loss: 0.6780 - val_binary_accuracy: 0.8294\n",
      "Epoch 15/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1628 - binary_accuracy: 0.9821 - val_loss: 0.7477 - val_binary_accuracy: 0.8282\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1873 - binary_accuracy: 0.9246 - val_loss: 0.4994 - val_binary_accuracy: 0.8367\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1286 - binary_accuracy: 0.9561 - val_loss: 0.4292 - val_binary_accuracy: 0.8529\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.1025 - binary_accuracy: 0.9633 - val_loss: 0.5419 - val_binary_accuracy: 0.8431\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0840 - binary_accuracy: 0.9697 - val_loss: 0.7187 - val_binary_accuracy: 0.8053\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0836 - binary_accuracy: 0.9714 - val_loss: 0.5689 - val_binary_accuracy: 0.8393\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0557 - binary_accuracy: 0.9819 - val_loss: 0.6476 - val_binary_accuracy: 0.8283\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0429 - binary_accuracy: 0.9858 - val_loss: 0.7049 - val_binary_accuracy: 0.8324\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0323 - binary_accuracy: 0.9899 - val_loss: 0.7342 - val_binary_accuracy: 0.8357\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0442 - binary_accuracy: 0.9863 - val_loss: 0.6811 - val_binary_accuracy: 0.8330\n",
      "Epoch 12/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0383 - binary_accuracy: 0.9876 - val_loss: 0.7524 - val_binary_accuracy: 0.8335\n",
      "For 64_0.01_False accuracy 0.8655 early_stopping 0.8641999959945679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_49_layer_call_fn, lstm_cell_49_layer_call_and_return_conditional_losses, lstm_cell_50_layer_call_fn, lstm_cell_50_layer_call_and_return_conditional_losses, lstm_cell_49_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/64_0.01_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/64_0.01_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 64_0.001_True\n",
      "<keras.regularizers.L1L2 object at 0x14cd2962b910>\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[17][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128)          0           bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            129         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "235/235 [==============================] - 26s 94ms/step - loss: 1.5856 - binary_accuracy: 0.5310 - val_loss: 0.7672 - val_binary_accuracy: 0.4990\n",
      "Epoch 2/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.7393 - binary_accuracy: 0.5007 - val_loss: 0.7187 - val_binary_accuracy: 0.4990\n",
      "Epoch 3/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.7102 - binary_accuracy: 0.5007 - val_loss: 0.7034 - val_binary_accuracy: 0.4990\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.7005 - binary_accuracy: 0.5007 - val_loss: 0.6987 - val_binary_accuracy: 0.4990\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6985 - binary_accuracy: 0.5007 - val_loss: 0.6978 - val_binary_accuracy: 0.4990\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6978 - binary_accuracy: 0.5007 - val_loss: 0.6982 - val_binary_accuracy: 0.4990\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6980 - binary_accuracy: 0.5007 - val_loss: 0.7004 - val_binary_accuracy: 0.4990\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6981 - binary_accuracy: 0.5007 - val_loss: 0.6968 - val_binary_accuracy: 0.4990\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6979 - binary_accuracy: 0.5007 - val_loss: 0.6969 - val_binary_accuracy: 0.4990\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.6976 - binary_accuracy: 0.5007 - val_loss: 0.6969 - val_binary_accuracy: 0.4990\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6975 - binary_accuracy: 0.5007 - val_loss: 0.6974 - val_binary_accuracy: 0.4990\n",
      "For 64_0.001_True accuracy 0.5143 early_stopping 0.49900001287460327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_52_layer_call_fn, lstm_cell_52_layer_call_and_return_conditional_losses, lstm_cell_53_layer_call_fn, lstm_cell_53_layer_call_and_return_conditional_losses, lstm_cell_52_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/64_0.001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/64_0.001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 64_0.001_False\n",
      "None\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[18][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_18 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1)            129         bi_lstm_0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "166/235 [====================>.........] - ETA: 4s - loss: 0.5333 - binary_accuracy: 0.7209Epoch 5/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.1844 - binary_accuracy: 0.9353 - val_loss: 0.3708 - val_binary_accuracy: 0.8693\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.1170 - binary_accuracy: 0.9657 - val_loss: 0.5735 - val_binary_accuracy: 0.8737\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0938 - binary_accuracy: 0.9767 - val_loss: 0.3722 - val_binary_accuracy: 0.8709\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.1025 - binary_accuracy: 0.9696 - val_loss: 0.4739 - val_binary_accuracy: 0.8724\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0518 - binary_accuracy: 0.9861 - val_loss: 0.4914 - val_binary_accuracy: 0.8721\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0386 - binary_accuracy: 0.9903 - val_loss: 0.3807 - val_binary_accuracy: 0.8486\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0311 - binary_accuracy: 0.9917 - val_loss: 0.4525 - val_binary_accuracy: 0.8657\n",
      "Epoch 12/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.1086 - binary_accuracy: 0.9606 - val_loss: 0.4975 - val_binary_accuracy: 0.8308\n",
      "Epoch 13/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.1279 - binary_accuracy: 0.9515 - val_loss: 0.4534 - val_binary_accuracy: 0.8101\n",
      "Epoch 14/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0848 - binary_accuracy: 0.9640 - val_loss: 0.5468 - val_binary_accuracy: 0.8645\n",
      "Epoch 15/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.0292 - binary_accuracy: 0.9931 - val_loss: 0.5299 - val_binary_accuracy: 0.8690\n",
      "Epoch 16/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.0203 - binary_accuracy: 0.9943 - val_loss: 0.5463 - val_binary_accuracy: 0.8670\n",
      "For 64_0.001_False accuracy 0.8737 early_stopping 0.8737000226974487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_55_layer_call_fn, lstm_cell_55_layer_call_and_return_conditional_losses, lstm_cell_56_layer_call_fn, lstm_cell_56_layer_call_and_return_conditional_losses, lstm_cell_55_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/64_0.001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_lstm_/64_0.001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 64_0.0001_True\n",
      "<keras.regularizers.L1L2 object at 0x14ccdcc76760>\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[19][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_19 (Attention)        (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_lstm_0 (Bidirectional)       (None, 128)          66048       attention_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 128)          0           bi_lstm_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1)            129         dropout_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,986,177\n",
      "Trainable params: 1,986,177\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "235/235 [==============================] - 26s 94ms/step - loss: 4.1337 - binary_accuracy: 0.5743 - val_loss: 3.3542 - val_binary_accuracy: 0.7151\n",
      "Epoch 2/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 2.8726 - binary_accuracy: 0.6809 - val_loss: 2.5653 - val_binary_accuracy: 0.5329\n",
      "Epoch 3/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 1.9508 - binary_accuracy: 0.8201 - val_loss: 1.7903 - val_binary_accuracy: 0.6761\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 1.4856 - binary_accuracy: 0.8143 - val_loss: 1.4034 - val_binary_accuracy: 0.7466\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 1.0689 - binary_accuracy: 0.8806 - val_loss: 1.0271 - val_binary_accuracy: 0.8611\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.8332 - binary_accuracy: 0.8835 - val_loss: 0.8592 - val_binary_accuracy: 0.8348\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.7500 - binary_accuracy: 0.8808 - val_loss: 0.8091 - val_binary_accuracy: 0.8547\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 21s 89ms/step - loss: 0.6527 - binary_accuracy: 0.9153 - val_loss: 0.7786 - val_binary_accuracy: 0.8536\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 21s 88ms/step - loss: 0.6143 - binary_accuracy: 0.9199 - val_loss: 0.7464 - val_binary_accuracy: 0.8596\n",
      "Epoch 10/200\n",
      "144/235 [=================>............] - ETA: 6s - loss: 0.5939 - binary_accuracy: 0.9193"
     ]
    }
   ],
   "source": [
    "model_fn = model.get_bidirectional_lstm_attention\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "results_l = main.run_experiment(model_fn, train_ds, val_ds, loss_fn, vectorizer, \"./results_lstm_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5a590-64be-41d1-b39c-6d856298e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.01_True\n",
      "<keras.regularizers.L1L2 object at 0x154469e8adf0>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)        (None, 128)          49920       attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           bi_gru_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            129         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,970,049\n",
      "Trainable params: 1,970,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 15:43:26.884002: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8902\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /common/cse479/shared/envs/tensorflow-env/lib/python3.9/site-packages/tensorflow/python/../../../../libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 37s 63ms/step - loss: 0.5419 - binary_accuracy: 0.7978 - val_loss: 0.4870 - val_binary_accuracy: 0.8142\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.2490 - binary_accuracy: 0.9310 - val_loss: 0.4299 - val_binary_accuracy: 0.8529\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1551 - binary_accuracy: 0.9685 - val_loss: 0.5339 - val_binary_accuracy: 0.8540\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1391 - binary_accuracy: 0.9795 - val_loss: 0.5267 - val_binary_accuracy: 0.8603\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0984 - binary_accuracy: 0.9875 - val_loss: 0.7097 - val_binary_accuracy: 0.8535\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0961 - binary_accuracy: 0.9894 - val_loss: 1.0283 - val_binary_accuracy: 0.8224\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0826 - binary_accuracy: 0.9911 - val_loss: 0.8095 - val_binary_accuracy: 0.8423\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0744 - binary_accuracy: 0.9943 - val_loss: 0.8655 - val_binary_accuracy: 0.8389\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1210 - binary_accuracy: 0.9901 - val_loss: 0.7748 - val_binary_accuracy: 0.8359\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 7.4078 - binary_accuracy: 0.9695 - val_loss: 6.2118 - val_binary_accuracy: 0.8066\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 4.3415 - binary_accuracy: 0.9862 - val_loss: 4.3049 - val_binary_accuracy: 0.8147\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 2.7747 - binary_accuracy: 0.9911 - val_loss: 3.1056 - val_binary_accuracy: 0.8049\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 5.3811 - binary_accuracy: 0.9897 - val_loss: 18.5532 - val_binary_accuracy: 0.8054\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 17.7612 - binary_accuracy: 0.9706 - val_loss: 18.4288 - val_binary_accuracy: 0.8051\n",
      "For 32_0.01_True accuracy 0.8622 early_stopping 0.8603000044822693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 15:50:15.106857: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn, gru_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.01_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.01_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.01_False\n",
      "None\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)        (None, 128)          49920       attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         bi_gru_0[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,970,049\n",
      "Trainable params: 1,970,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 34s 63ms/step - loss: 0.3474 - binary_accuracy: 0.8373 - val_loss: 0.2679 - val_binary_accuracy: 0.8834\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1391 - binary_accuracy: 0.9475 - val_loss: 0.3726 - val_binary_accuracy: 0.8575\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0798 - binary_accuracy: 0.9693 - val_loss: 0.6079 - val_binary_accuracy: 0.8516\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0717 - binary_accuracy: 0.9736 - val_loss: 0.5850 - val_binary_accuracy: 0.8388\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1843 - binary_accuracy: 0.9251 - val_loss: 0.5892 - val_binary_accuracy: 0.7689\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.2744 - binary_accuracy: 0.8811 - val_loss: 0.5234 - val_binary_accuracy: 0.7984\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.2009 - binary_accuracy: 0.9169 - val_loss: 0.5889 - val_binary_accuracy: 0.7951\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1661 - binary_accuracy: 0.9325 - val_loss: 0.5727 - val_binary_accuracy: 0.8087\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1436 - binary_accuracy: 0.9445 - val_loss: 0.6155 - val_binary_accuracy: 0.8104\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1244 - binary_accuracy: 0.9505 - val_loss: 0.6424 - val_binary_accuracy: 0.8017\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1091 - binary_accuracy: 0.9557 - val_loss: 0.6811 - val_binary_accuracy: 0.8087\n",
      "For 32_0.01_False accuracy 0.8878 early_stopping 0.883400022983551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.01_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.01_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.001_True\n",
      "<keras.regularizers.L1L2 object at 0x15434a2f8df0>\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)        (None, 128)          49920       attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           bi_gru_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,970,049\n",
      "Trainable params: 1,970,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1204 - binary_accuracy: 0.9712 - val_loss: 0.4808 - val_binary_accuracy: 0.8857\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0813 - binary_accuracy: 0.9835 - val_loss: 0.5145 - val_binary_accuracy: 0.8819\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0697 - binary_accuracy: 0.9876 - val_loss: 0.4305 - val_binary_accuracy: 0.8483\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1334 - binary_accuracy: 0.9643 - val_loss: 0.4341 - val_binary_accuracy: 0.8714\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0528 - binary_accuracy: 0.9920 - val_loss: 0.5774 - val_binary_accuracy: 0.8775\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1706 - binary_accuracy: 0.9783 - val_loss: 0.7018 - val_binary_accuracy: 0.8739\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0441 - binary_accuracy: 0.9958 - val_loss: 0.7427 - val_binary_accuracy: 0.8764\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0394 - binary_accuracy: 0.9950 - val_loss: 0.6765 - val_binary_accuracy: 0.8763\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0270 - binary_accuracy: 0.9981 - val_loss: 0.5931 - val_binary_accuracy: 0.8737\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0431 - binary_accuracy: 0.9931 - val_loss: 0.7539 - val_binary_accuracy: 0.8718\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0225 - binary_accuracy: 0.9983 - val_loss: 0.7697 - val_binary_accuracy: 0.8780\n",
      "For 32_0.001_True accuracy 0.887 early_stopping 0.885699987411499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_7_layer_call_and_return_conditional_losses, gru_cell_7_layer_call_fn, gru_cell_8_layer_call_and_return_conditional_losses, gru_cell_8_layer_call_fn, gru_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.001_True/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.001_False\n",
      "None\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[3][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)        (None, 128)          49920       attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         bi_gru_0[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,970,049\n",
      "Trainable params: 1,970,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 96/469 [=====>........................] - ETA: 17s - loss: 0.5600 - binary_accuracy: 0.6504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0142 - binary_accuracy: 0.9952 - val_loss: 0.7020 - val_binary_accuracy: 0.8656\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0111 - binary_accuracy: 0.9962 - val_loss: 0.4452 - val_binary_accuracy: 0.8642\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0085 - binary_accuracy: 0.9973 - val_loss: 0.7722 - val_binary_accuracy: 0.8680\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0033 - binary_accuracy: 0.9991 - val_loss: 0.8584 - val_binary_accuracy: 0.8660\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0072 - binary_accuracy: 0.9975 - val_loss: 0.8904 - val_binary_accuracy: 0.8662\n",
      "For 32_0.001_False accuracy 0.8896 early_stopping 0.8866999745368958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_10_layer_call_and_return_conditional_losses, gru_cell_10_layer_call_fn, gru_cell_11_layer_call_and_return_conditional_losses, gru_cell_11_layer_call_fn, gru_cell_10_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results_gru_/32_0.001_False/best_model.hd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 32_0.0001_True\n",
      "<keras.regularizers.L1L2 object at 0x154331a07a90>\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 1200)         0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1200, 64)     1920000     text_vectorization[4][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 1200, 64)     0           embedding[0][0]                  \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bi_gru_0 (Bidirectional)        (None, 128)          49920       attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           bi_gru_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,970,049\n",
      "Trainable params: 1,970,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "469/469 [==============================] - 34s 63ms/step - loss: 3.2256 - binary_accuracy: 0.5974 - val_loss: 2.1426 - val_binary_accuracy: 0.8293\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 1.6100 - binary_accuracy: 0.8666 - val_loss: 1.2640 - val_binary_accuracy: 0.8647\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.9645 - binary_accuracy: 0.8896 - val_loss: 0.8422 - val_binary_accuracy: 0.8627\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.6372 - binary_accuracy: 0.9095 - val_loss: 0.6688 - val_binary_accuracy: 0.8728\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.5207 - binary_accuracy: 0.9269 - val_loss: 0.6600 - val_binary_accuracy: 0.8702\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.6014 - binary_accuracy: 0.8728 - val_loss: 0.6332 - val_binary_accuracy: 0.8760\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.4107 - binary_accuracy: 0.9521 - val_loss: 0.6223 - val_binary_accuracy: 0.8794\n",
      "Epoch 8/200\n",
      "268/469 [================>.............] - ETA: 9s - loss: 0.3701 - binary_accuracy: 0.9588"
     ]
    }
   ],
   "source": [
    "model_fn = model.get_bidirectional_gru_attention\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "results_g = main.run_experiment(model_fn, train_ds, val_ds, loss_fn, vectorizer, \"./results_gru_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d792c1f-d38f-4901-915c-904e66d1901f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_m\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_m' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426d527-0377-4c7d-a583-11b80d5f707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = results_l #pd.concat([results_l],reset_index=True, sort=False)\n",
    "best_result = combined_results[combined_results['accuracy']==combined_results['accuracy'].max()]\n",
    "weight_location = best_result['model']\n",
    "if \"lstm\" in weight_location:\n",
    "    f_model = model.get_bidirectional_lstm_attention(vectorizer)\n",
    "else:\n",
    "    f_model = model.get_bidirectional_gru_attention(vectorizer)\n",
    "    \n",
    "        \n",
    "f_model.load_weights(weight_location)\n",
    "test_ds = util.get_test_ds()\n",
    "util.evaluate_model(f_model, test_ds, Path(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b8e87d8-87c2-4f17-afa6-5a91a3f76db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "best_model = model.get_bidirectional_lstm_attention(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec55cab8-27bc-4ea7-8a51-eb42345fe190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x14c3902738e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.load_weights(\"results_lstm_/32_0.001_True/best_weights.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22a5423a-79cd-4f0b-937b-5ff784e727ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8889"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = util.get_test_ds()\n",
    "util.evaluate_model(best_model, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ace762f0-8a09-4318-9bd3-6a3875bdbde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGwCAYAAABb6kfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA400lEQVR4nO3deVyU5f7/8fewDpqDIoIbImYuqaVBGXpsj7LlaP1OUZZZYWVWHo6tfi23SrJTZlaQtqltx06LbWaHU5mUpzoSrZqVmaCCCCogyjZz//4gOY2MNsPMgDP36/l43A+de67rvj+j8+DD57qu+74thmEYAgAAQSGkrQMAAAC+Q2IHACCIkNgBAAgiJHYAAIIIiR0AgCBCYgcAIIiQ2AEACCJhbR2ANxwOh7Zv364OHTrIYrG0dTgAAA8ZhqGqqip1795dISH+qzVrampUV1fn9XEiIiJktVp9EJH/BHRi3759uxISEto6DACAl4qKitSzZ0+/HLumpkZJiUeppNTu9bG6du2qzZs3H9HJPaATe4cOHSRJW77sLdtRzCogOF3Ub0hbhwD4TYPq9YlWNv0894e6ujqVlNq1Jb+3bB1anisqqxxKTP5VdXV1JHZ/OTD8bjsqxKv/LOBIFmYJb+sQAP/57abmrTGdelQHi47q0PLzOBQYU74BndgBAHCX3XDI7sXTUeyGw3fB+BGJHQBgCg4Zcqjlmd2bvq2J8WsAAIIIFTsAwBQccsibwXTverceEjsAwBTshiG70fLhdG/6tiaG4gEACCJU7AAAUzDL4jkSOwDAFBwyZDdBYmcoHgCAIELFDgAwBYbiAQAIIqyKBwAAAYeKHQBgCo7fNm/6BwISOwDAFOxeror3pm9rIrEDAEzBbsjLp7v5LhZ/Yo4dAIAgQsUOADAF5tgBAAgiDllkl8Wr/oGAoXgAAIIIFTsAwBQcRuPmTf9AQGIHAJiC3cuheG/6tiaG4gEACCJU7AAAUzBLxU5iBwCYgsOwyGF4sSrei76tiaF4AACCCBU7AMAUGIoHACCI2BUiuxcD1XYfxuJPJHYAgCkYXs6xG8yxAwCA1kbFDgAwBebYAQAIInYjRHbDizn2ALmlLEPxAAAEESp2AIApOGSRw4t61qHAKNlJ7AAAUzDLHDtD8QAA+FF2draSkpJktVqVnJysvLy8w7Z/8cUXdfzxx6tdu3bq1q2brrnmGpWXl7t9PhI7AMAUDiye82bz1PLly5WZmanp06eroKBAo0aN0ujRo1VYWOiy/SeffKKrrrpKGRkZ+v777/XPf/5T//3vfzVx4kS3z0liBwCYQuMcu3ebJFVWVjpttbW1hzzn/PnzlZGRoYkTJ2rgwIFasGCBEhISlJOT47L9Z599pt69e2vKlClKSkrSn/70J91www1at26d25+TxA4AgAcSEhIUHR3dtGVlZblsV1dXp/z8fKWlpTntT0tL09q1a132GTFihLZu3aqVK1fKMAzt2LFDr776qs4//3y342PxHADAFBxe3iv+wKr4oqIi2Wy2pv2RkZEu25eVlclutys+Pt5pf3x8vEpKSlz2GTFihF588UWlp6erpqZGDQ0N+vOf/6zHHnvM7Tip2AEApuCrOXabzea0HSqxH2CxOK+mNwyj2b4D1q9frylTpmjGjBnKz8/XqlWrtHnzZk2aNMntz0nFDgAwBYdCWvU69tjYWIWGhjarzktLS5tV8QdkZWVp5MiRuv322yVJxx13nNq3b69Ro0bpvvvuU7du3f7wvFTsAAD4QUREhJKTk5Wbm+u0Pzc3VyNGjHDZZ9++fQoJcU7NoaGhkhorfXdQsQMATMFuWGT34tGrLek7depUjR8/XikpKUpNTdXixYtVWFjYNLQ+bdo0bdu2TcuWLZMkXXjhhbruuuuUk5Ojc845R8XFxcrMzNRJJ52k7t27u3VOEjsAwBTsXi6es7fglrLp6ekqLy/XnDlzVFxcrMGDB2vlypVKTEyUJBUXFztd03711VerqqpKjz/+uG699VZ17NhRZ5xxhubNm+f2OS2Gu7X9EaiyslLR0dHa/WMf2Towq4DgdE73oW0dAuA3DUa9VutNVVRUOK0096UDuWJJwfFq1yG0xcfZV2XX1cO+9musvkDFDgAwBYcRIocXj211BEgdTGIHAJhCWwzFtwXGrwEACCJU7AAAU3CoZSvbf98/EJDYAQCm4P0NagJjkDswogQAAG6hYgcAmEJLn6n++/6BgMQOADCF3z9TvaX9AwGJHQBgCmap2AMjSgAA4BYqdgCAKXh/g5rAqIVJ7AAAU3AYFjm8uY7di76tKTB+/QAAAG6hYgcAmILDy6H4QLlBDYkdAGAK3j/dLTASe2BECQAA3ELFDgAwBbsssntxkxlv+rYmEjsAwBQYigcAAAGHih0AYAp2eTecbvddKH5FYgcAmIJZhuJJ7AAAU+AhMAAAIOBQsQMATMHw8nnsBpe7AQBw5GAoHgAABBwqdgCAKZjlsa0kdgCAKdi9fLqbN31bU2BECQAA3ELFDgAwBYbiAQAIIg6FyOHFQLU3fVtTYEQJAADcQsUOADAFu2GR3YvhdG/6tiYSOwDAFJhjBwAgiBhePt3N4M5zAACgtVGxAwBMwS6L7F48yMWbvq2Jih0AYAoO43/z7C3bWnbe7OxsJSUlyWq1Kjk5WXl5eYdse/XVV8tisTTbBg0a5Pb5SOwAAPjJ8uXLlZmZqenTp6ugoECjRo3S6NGjVVhY6LL9o48+quLi4qatqKhIMTExuuSSS9w+J0PxJvf2ks76Z06cdpWGK7FfjSbN2aYhw6sP2f7D1zvplew4bf8lUu1tdiWfVqnrZ2yXLcbe1Ob1p7ro3aWdVbo9QrZODRp1wR5dO61YEdYW/roLeOGCCWW65Madiomr15YfrXpyRnd998VRLtvGxNXr+pnb1fe4/eqRVKs3n4nVkzN7OLUZPa5cZ12yW4n9ayRJP38bpeeyumnjV+38/lngHYeXi+cO9K2srHTaHxkZqcjISJd95s+fr4yMDE2cOFGStGDBAr3//vvKyclRVlZWs/bR0dGKjo5uer1ixQrt3r1b11xzjdtxUrGb2Oo3O+rJmT10+ZQdyv7XRg0eXq27r+ij0q3hLtt/93l7/X1KL517WbkWr/5B0xf9qh+/bqdHbktoavPh65307NxuumJqiZ76+AdNfbhIH7/VSc9mdWutjwU0OfXPuzVp9na9vDBOk9P66bvP2+u+FzerS486l+3DIwztKQ/TPx6N0y/rrS7bHDdirz5a0VF3XHK0/vbnvirdFq65L29S5671/vwo8AGHLF5vkpSQkNCUgKOjo10maEmqq6tTfn6+0tLSnPanpaVp7dq1bsX8zDPP6KyzzlJiYqLbn7PNE7sncw/wrdcXd9E5l+/S6Ct2qdcxtbpxzjZ16V6vd5bFumy/4ct2ik+o09iJZeraq06Dh1fr/CvL9ePX/6tU1q9rp0EnVuuMi/eoa0Kdkk+r0mljdzu1AVrLxdeX6f2XY7Tqpc4q+tmqJ2f20M7t4brgqnKX7XdsjdCTM3ro36/GqLoy1GWbeTcn6p2lsfrl+ygV/WzVgtsSZAmRhv2pyp8fBUeQoqIiVVRUNG3Tpk1z2a6srEx2u13x8fFO++Pj41VSUvKH5ykuLtZ7773XVO27q00Tu6dzD/Cd+jqLfvqmnZJPdf5hlHxqldava++yz7Ep1SorDtcXH3SQYUi7d4Yp792OOums/w1LDT6pWj99004/FDQm8uItEfrvBzYNP7PS5TEBfwkLd+iY4/Yp/+MOTvvzP+6gY1MOPd3kqcgoh8LCDFXtYWbzSHfgznPebJJks9mctkMNwx9gsTivpjcMo9k+V5YsWaKOHTtq7NixHn3ONv0mejr3AN+p3BUqh92ijrHOw4cdu9Rrd2kHl30GnbhPdz6+RXMn9VZdbYjsDRadnFahm+7b2tTmtLF7VFEeplvH9pVhWGRvsOiCCWVKv6XUr58HOJgtxq7QMGlPmfOPuT07w9QprsFn57l2erHKS8L1ZZ7reXscOXw1x+6u2NhYhYaGNqvOS0tLm1XxBzMMQ88++6zGjx+viIgIj87bZhV7S+YeamtrVVlZ6bTBOwf/0mgYFh3qUs0tP0Yq+56euuJvJXp81Ubd/9Im7SiK0MI7/zfH/vXao/TywnjdPHernnh/o2Y8s1mf59r04iOH/xID/mIctGbTYpHko3Wcl0wu1elj9mjOxN6qr23zmU0cYSIiIpScnKzc3Fyn/bm5uRoxYsRh+3788cf6+eeflZGR4fF526xib8ncQ1ZWlmbPnt0a4QU9W4xdIaGGdu90XihXURamTl1cVzPLH4vXoBOrdcnknZKkPsfWyBq1VbdedIwm3FmszvENWvpgV535/3Zr9BW7JElJA2tUsy9Ej96eoMv/ukMh/OxDK6ncFSp7g5p9n6NjG7R7p/c/+v4yqVSX3bJDd6Ufrc0borw+HvzPIS/vFd+CG9RMnTpV48ePV0pKilJTU7V48WIVFhZq0qRJkqRp06Zp27ZtWrZsmVO/Z555RsOHD9fgwYM9Pmeb/5j1ZO5h2rRpTgsWioqKWiPEoBQeYeiY4/bpyzXOw+5frjn0/GPN/hBZLM6lTkjob69/+6N2f4gsIQe1CTFkqHnlBPhTQ32IfvqmnU44xXkdyQmnHHodibv+cmOpxmXu0PQr+uinb1gYGigML1fEGy1I7Onp6VqwYIHmzJmjoUOHas2aNVq5cmXTKvfi4uJm68oqKir02muvtahal9qwYm/J3MPhrhWE5y6+fqf+PqWX+h23TwNTqrXyhc4q3Rau868qkyQ9O7ebykrCdcfCxi/dyWdXasHtCXp76V6lnFalXTvC9eTMHuo/rFqduzY0tXl9cRf1HbxfA07Yp22bI7T079108tkVCnW9yBjwm9cXx+r2hUX68ZsobVjXXuddWa64HvV6d1lnSdI104oV27Vef/9rr6Y+fQbtlyRFtXcounOD+gzar4Y6iwp/arz87ZLJpbrq9hLNu6mXdhRFqFOXxnUq+6tDVLOPL/mRrK2e7jZ58mRNnjzZ5XtLlixpti86Olr79u1r0bmkNkzsv597uOiii5r25+bmasyYMW0VlqmcNmaPqnaH6sVHumpXaZgS+9fovhd+UXzPxh9Uu0rDtXPb/xZtpKXv0v69IXrruVg9NbuH2kfbNXRklTKmFze1GZdZIovF0JIHu6m8JFzRMQ06+ewKXX3XH1/aAfjax291UodOdl3xtx2KiWvQlo1W3X1lkkp/+17HxNU3u6Y9J/fHpr/3O36/zrh4j0qKwjVh+LGSGm94ExFp6J6ntzj1e/7heL3wcFc/fyLgj1kMo+0GSJcvX67x48frySefbJp7eOqpp/T999+7dTF+ZWWloqOjtfvHPrJ1aPNZBcAvzuk+tK1DAPymwajXar2piooK2Ww2v5zjQK64KPcahbf3bIX579VX1+mNs5/za6y+0KaXu6Wnp6u8vFxz5sxRcXGxBg8e7DT3AACAr7TVUHxra/M7Khxu7gEAAHimzRM7AACt4ff3e29p/0BAYgcAmIJZhuJZcQYAQBChYgcAmIJZKnYSOwDAFMyS2BmKBwAgiFCxAwBMwSwVO4kdAGAKhry7ZC1QnmNFYgcAmIJZKnbm2AEACCJU7AAAUzBLxU5iBwCYglkSO0PxAAAEESp2AIApmKViJ7EDAEzBMCwyvEjO3vRtTQzFAwAQRKjYAQCmwPPYAQAIImaZY2coHgCAIELFDgAwBbMsniOxAwBMwSxD8SR2AIApmKViZ44dAIAgQsUOADAFw8uh+ECp2EnsAABTMCQZhnf9AwFD8QAABBEqdgCAKThkkYU7zwEAEBxYFQ8AAAIOFTsAwBQchkUWblADAEBwMAwvV8UHyLJ4huIBAAgiVOwAAFNg8RwAAEHkQGL3ZmuJ7OxsJSUlyWq1Kjk5WXl5eYdtX1tbq+nTpysxMVGRkZE6+uij9eyzz7p9Pip2AIAptMXiueXLlyszM1PZ2dkaOXKkFi1apNGjR2v9+vXq1auXyz6XXnqpduzYoWeeeUZ9+/ZVaWmpGhoa3D4niR0AAD+ZP3++MjIyNHHiREnSggUL9P777ysnJ0dZWVnN2q9atUoff/yxfvnlF8XExEiSevfu7dE5GYoHAJjCgVXx3mySVFlZ6bTV1ta6PF9dXZ3y8/OVlpbmtD8tLU1r16512eett95SSkqKHnzwQfXo0UP9+vXTbbfdpv3797v9OanYAQCm0JicvVk81/hnQkKC0/6ZM2dq1qxZzdqXlZXJbrcrPj7eaX98fLxKSkpcnuOXX37RJ598IqvVqjfeeENlZWWaPHmydu3a5fY8O4kdAAAPFBUVyWazNb2OjIw8bHuLxfmXCcMwmu07wOFwyGKx6MUXX1R0dLSkxuH8v/zlL3riiScUFRX1h/GR2AEApuCry91sNptTYj+U2NhYhYaGNqvOS0tLm1XxB3Tr1k09evRoSuqSNHDgQBmGoa1bt+qYY475w/Myxw4AMAXDB5snIiIilJycrNzcXKf9ubm5GjFihMs+I0eO1Pbt27V3796mfT/++KNCQkLUs2dPt85LYgcAwE+mTp2qp59+Ws8++6w2bNigv/3tbyosLNSkSZMkSdOmTdNVV13V1H7cuHHq3LmzrrnmGq1fv15r1qzR7bffrmuvvdatYXiJoXgAgEm0xZ3n0tPTVV5erjlz5qi4uFiDBw/WypUrlZiYKEkqLi5WYWFhU/ujjjpKubm5uuWWW5SSkqLOnTvr0ksv1X333ef2OUnsAABzaMl4+sH9W2Dy5MmaPHmyy/eWLFnSbN+AAQOaDd97gsQOADAHLyt2ca94AADQ2qjYAQCmYJbnsZPYAQCmwGNbAQBAwKFiBwCYg2HxbgFcgFTsJHYAgCmYZY6doXgAAIIIFTsAwBza6AY1rY3EDgAwBbOsincrsS9cuNDtA06ZMqXFwQAAAO+4ldgfeeQRtw5msVhI7ACAI1eADKd7w63EvnnzZn/HAQCAX5llKL7Fq+Lr6uq0ceNGNTQ0+DIeAAD8w/DBFgA8Tuz79u1TRkaG2rVrp0GDBjU9R3bKlCl64IEHfB4gAABwn8eJfdq0afr666+1evVqWa3Wpv1nnXWWli9f7tPgAADwHYsPtiOfx5e7rVixQsuXL9fJJ58si+V/H/LYY4/Vpk2bfBocAAA+Y5Lr2D2u2Hfu3Km4uLhm+6urq50SPQAAaH0eJ/YTTzxR7777btPrA8n8qaeeUmpqqu8iAwDAl0yyeM7jofisrCyde+65Wr9+vRoaGvToo4/q+++/13/+8x99/PHH/ogRAADvmeTpbh5X7CNGjNCnn36qffv26eijj9a//vUvxcfH6z//+Y+Sk5P9ESMAAHBTi+4VP2TIEC1dutTXsQAA4DdmeWxrixK73W7XG2+8oQ0bNshisWjgwIEaM2aMwsJ4pgwA4AhlklXxHmfi7777TmPGjFFJSYn69+8vSfrxxx/VpUsXvfXWWxoyZIjPgwQAAO7xeI594sSJGjRokLZu3aovv/xSX375pYqKinTcccfp+uuv90eMAAB478DiOW+2AOBxxf71119r3bp16tSpU9O+Tp066f7779eJJ57o0+AAAPAVi9G4edM/EHhcsffv3187duxotr+0tFR9+/b1SVAAAPicSa5jdyuxV1ZWNm1z587VlClT9Oqrr2rr1q3aunWrXn31VWVmZmrevHn+jhcAAByGW0PxHTt2dLpdrGEYuvTSS5v2Gb9dA3DhhRfKbrf7IUwAALxkkhvUuJXYP/roI3/HAQCAf3G52/+ceuqp/o4DAAD4QIvvKLNv3z4VFhaqrq7Oaf9xxx3ndVAAAPgcFbtrO3fu1DXXXKP33nvP5fvMsQMAjkgmSeweX+6WmZmp3bt367PPPlNUVJRWrVqlpUuX6phjjtFbb73ljxgBAICbPK7YP/zwQ7355ps68cQTFRISosTERJ199tmy2WzKysrS+eef7484AQDwjklWxXtcsVdXVysuLk6SFBMTo507d0pqfOLbl19+6dvoAADwkQN3nvNmCwQtuvPcxo0bJUlDhw7VokWLtG3bNj355JPq1q2bzwMEAADua9Ece3FxsSRp5syZWrVqlXr16qWFCxdq7ty5Pg8QAACfaKNbymZnZyspKUlWq1XJycnKy8s7ZNvVq1fLYrE023744Qe3z+fxHPsVV1zR9Pdhw4bp119/1Q8//KBevXopNjbW08MBABC0li9frszMTGVnZ2vkyJFatGiRRo8erfXr16tXr16H7Ldx40bZbLam1126dHH7nB5X7Adr166dTjjhBJI6AOCIZpGXc+wtOOf8+fOVkZGhiRMnauDAgVqwYIESEhKUk5Nz2H5xcXHq2rVr0xYaGur2Od2q2KdOner2AefPn+92WwAAAk1lZaXT68jISEVGRjZrV1dXp/z8fN11111O+9PS0rR27drDnmPYsGGqqanRscceq7vvvlunn3662/G5ldgLCgrcOtjvHxTTmi4ekqIwS3ibnBvwt9e2ftzWIQB+U1nlUMKAVjqZjy53S0hIcNo9c+ZMzZo1q1nzsrIy2e12xcfHO+2Pj49XSUmJy1N069ZNixcvVnJysmpra/X888/rzDPP1OrVq3XKKae4FSYPgQEAmIOP7jxXVFTkNP/tqlr/vYOLXsMwDlkI9+/fX/379296nZqaqqKiIj300ENuJ3av59gBADATm83mtB0qscfGxio0NLRZdV5aWtqsij+ck08+WT/99JPb7UnsAABzaOXL3SIiIpScnKzc3Fyn/bm5uRoxYoTbxykoKPDoPjEtfrobAACBxNu7x7Wk79SpUzV+/HilpKQoNTVVixcvVmFhoSZNmiRJmjZtmrZt26Zly5ZJkhYsWKDevXtr0KBBqqur0wsvvKDXXntNr732mtvnJLEDAOAn6enpKi8v15w5c1RcXKzBgwdr5cqVSkxMlCQVFxersLCwqX1dXZ1uu+02bdu2TVFRURo0aJDeffddnXfeeW6f02IYRoDc/ba5yspKRUdH6/TIS1kVj6D16iZWxSN4Na6K366KigqnBWk+PcdvuaL3ffcrxGpt8XEcNTX69e7pfo3VF1o0x/78889r5MiR6t69u7Zs2SKpcfjgzTff9GlwAAD4TBvdUra1eZzYc3JyNHXqVJ133nnas2eP7Ha7JKljx45asGCBr+MDAAAe8DixP/bYY3rqqac0ffp0p1vcpaSk6Ntvv/VpcAAA+IpZHtvq8eK5zZs3a9iwYc32R0ZGqrq62idBAQDgcz6689yRzuOKPSkpSV999VWz/e+9956OPfZYX8QEAIDvmWSO3eOK/fbbb9dNN92kmpoaGYahL774Qi+//LKysrL09NNP+yNGAADgJo8T+zXXXKOGhgbdcccd2rdvn8aNG6cePXro0Ucf1WWXXeaPGAEA8Fpb3KCmLbToBjXXXXedrrvuOpWVlcnhcCguLs7XcQEA4Fs+egjMkc6rO8/Fxsb6Kg4AAOADHif2pKSkwz53/ZdffvEqIAAA/MLbS9aCtWLPzMx0el1fX6+CggKtWrVKt99+u6/iAgDAtxiKd+2vf/2ry/1PPPGE1q1b53VAAACg5Xz2PPbRo0d79Fg5AABaFdexe+bVV19VTEyMrw4HAIBPcbnbIQwbNsxp8ZxhGCopKdHOnTuVnZ3t0+AAAIBnPE7sY8eOdXodEhKiLl266LTTTtOAAQN8FRcAAGgBjxJ7Q0ODevfurXPOOUddu3b1V0wAAPieSVbFe7R4LiwsTDfeeKNqa2v9FQ8AAH5hlse2erwqfvjw4SooKPBHLAAAwEsez7FPnjxZt956q7Zu3ark5GS1b9/e6f3jjjvOZ8EBAOBTAVJ1e8PtxH7ttddqwYIFSk9PlyRNmTKl6T2LxSLDMGSxWGS3230fJQAA3jLJHLvbiX3p0qV64IEHtHnzZn/GAwAAvOB2YjeMxl9VEhMT/RYMAAD+wg1qXDjcU90AADiiMRTfXL9+/f4wue/atcurgAAAQMt5lNhnz56t6Ohof8UCAIDfMBTvwmWXXaa4uDh/xQIAgP+YZCje7RvUML8OAMCRz+NV8QAABCSTVOxuJ3aHw+HPOAAA8Cvm2AEACCYmqdg9fggMAAA4clGxAwDMwSQVO4kdAGAKZpljZygeAIAgQsUOADAHhuIBAAgeDMUDAICAQ2IHAJiD4YOtBbKzs5WUlCSr1ark5GTl5eW51e/TTz9VWFiYhg4d6tH5SOwAAHNog8S+fPlyZWZmavr06SooKNCoUaM0evRoFRYWHrZfRUWFrrrqKp155pken5PEDgCAByorK5222traQ7adP3++MjIyNHHiRA0cOFALFixQQkKCcnJyDnuOG264QePGjVNqaqrH8ZHYAQCmYPHBJkkJCQmKjo5u2rKyslyer66uTvn5+UpLS3Pan5aWprVr1x4yzueee06bNm3SzJkzW/Q5WRUPADAHH13uVlRUJJvN1rQ7MjLSZfOysjLZ7XbFx8c77Y+Pj1dJSYnLPj/99JPuuusu5eXlKSysZSmaxA4AMAVfXe5ms9mcEvsf9rNYnF4bhtFsnyTZ7XaNGzdOs2fPVr9+/VocJ4kdAAA/iI2NVWhoaLPqvLS0tFkVL0lVVVVat26dCgoKdPPNN0tqfGS6YRgKCwvTv/71L51xxhl/eF4SOwDAHFr5znMRERFKTk5Wbm6uLrrooqb9ubm5GjNmTLP2NptN3377rdO+7Oxsffjhh3r11VeVlJTk1nlJ7AAA82jlu8dNnTpV48ePV0pKilJTU7V48WIVFhZq0qRJkqRp06Zp27ZtWrZsmUJCQjR48GCn/nFxcbJarc32Hw6JHQAAP0lPT1d5ebnmzJmj4uJiDR48WCtXrlRiYqIkqbi4+A+vafeUxTCMALn7bXOVlZWKjo7W6ZGXKswS3tbhAH7x6qaP2zoEwG8qqxxKGLBdFRUVHi1I8+gcv+WKwdfPVWiEtcXHsdfV6LvF/+fXWH2Bih0AYA4mebobN6gBACCIULEDAEzBLI9tJbEDAMyBoXgAABBoqNgBAKbAUDwAAMHEJEPxJHYAgDmYJLEzxw4AQBChYgcAmAJz7AAABBOG4gEAQKChYgcAmILFMGTx4rln3vRtTSR2AIA5MBQPAAACDRU7AMAUWBUPAEAwYSgeAAAEGip2AIApMBQPAEAwMclQPIkdAGAKZqnYmWMHACCIULEDAMyBoXgAAIJLoAyne4OheAAAgggVOwDAHAyjcfOmfwAgsQMATIFV8QAAIOBQsQMAzIFV8QAABA+Lo3Hzpn8gYCgeAIAgQsVuchdcuUN/ub5YMXH12vJjlJ68N1Hf/7eDy7YxXep03fRCHTNkn7r3rtGbS+K16N5EpzYjz9ml9Mnb1b13rcLCDG371arXn+6qD96IbY2PAzSzamm83nyym3aXRiih3z5dM2uLjh1edcj2a17vrBU53VW82ap2NruGnbZHE+4pVIdODZKkGX85Vt9/ZmvW74Qzdmv6so1++xzwAYbiEexOOb9cN9xTqCdmJOr7dR103rhS3ffcRl2fNkQ7t0c2ax8eYahiV7hefqK7Lrq2xOUxq/aE6R9PdFfRpig11Ft00hl7NPXBX7SnPEz5azr6+RMBzj59q7Oem5Wo6+7frAEnVulfL8Tr/vEDtOCjr9WlR12z9hu+6KDHMvvq6plblHL2bu0qidCiaUnKvq2P7nzmR0nS7U9tVEP9/wY7q3aH6da045R6wa5W+1xoGVbFt4I1a9bowgsvVPfu3WWxWLRixYq2DMd0Lp5Yovdf6aJVy+NUtClKi+5N1M7iCF1wRanL9ju2RerJOYn64PVY7asKddnmm89tWvuvGBVtilJxoVVvLumqzT+006CUvf78KIBLby/upjMu26mzxu1Uz2NqdO3sLercvU7vL4t32f7HL49Sl4RanZ9RovhetRp4UpXSrtihTd+0b2rToZNdneLqm7Zv8qIVGWXXiAvKW+tjoaUOXMfuzRYA2jSxV1dX6/jjj9fjjz/elmGYUli4Q8cMrtaXec5Dil/mRWtgsq+SsKGhIyrUs0+Nvv3C9fA+4C/1dRZt+ra9hp6yx2n/8afs0cZ1rr+P/VOqVF4cofwPOsowpD07w/Wfdzsr+cw9LttL0gcvx2nkn8tlbRcgK6sQ9Np0KH706NEaPXq02+1ra2tVW1vb9LqystIfYZmCrVODQsOk3WXhTvt3l4Urpku9V8du16FBL/7nK4VHGHI4pMfv6a2CT6K9OibgqapdYXLYLYo+6PvcsUu99uwMd9lnQMpeZS78WfMnH6P6WovsDSE6MW2XMu791WX7nwraq3BjO01+aJOvw4cfmGUoPqDm2LOysjR79uy2DiO4HPRFtVi8H23avzdUk88frKh2dg0dWanr7y5USWGkvvm8+YIjwN8sFufXhiHJ4rKpin6M0jMze+uSzK0aemqFdpeGa9l9vbToriTd9PAvzdp/8I849eq/T8cMq/Z94PA9kyyeC6jL3aZNm6aKioqmraioqK1DCliVu8Nkb5A6HVzNdK5vVsV7yjAsKt5i1S8b2uv1p7vpk/dilD55u1fHBDzVIaZBIaGG9pQ6f58rysLVMdb1qNTrj3fXgJQqjb2xWL2P3adhp1Xo+rm/6sPlcdq9w/k4tftD9OlbnXXm5a7XpAAHZGdnKykpSVarVcnJycrLyztk208++UQjR45U586dFRUVpQEDBuiRRx7x6HwBldgjIyNls9mcNrRMQ32IfvquvYb9yXk6Y9ifKrQh/yifnssiQ+ERAfKrLoJGeISho4dU6+s852mgb/Ki1T/F9eVutftDZDnop2JIaON39+CRrE/f7qz6uhCd+v/KfBYz/OvAULw3m6eWL1+uzMxMTZ8+XQUFBRo1apRGjx6twsJCl+3bt2+vm2++WWvWrNGGDRt099136+6779bixYvdPmdAJXb41utPd9W56TuVdslOJRy9X9ffvUVx3ev07ktxkqRrbi/SbQ87zx32GVitPgOrZW1nV3RMg/oMrFavvvub3k+/cbuG/alCXRNq1LPPfl2cUawzLy7Xhys6t+pnAyTpwuuL9cHLcfrgH1209SernpuVqLJtkUobv0OS9EJWghb+9eim9iln79Hn73XSqmXxKtkSqR/+e5SemdFbxwzdq5iuzlX+h//oopPO2dV0fTsCgI9WxVdWVjptv1/7dbD58+crIyNDEydO1MCBA7VgwQIlJCQoJyfHZfthw4bp8ssv16BBg9S7d29deeWVOueccw5b5R8soObY4Vtr3u0sW6cGXTFlmzp1abxBzT3X9lPptsZr2GPi6hXX3fla3+yV3zf9vd9x+3TG2HLt2BqhCaOGSpKs7Ry6ec6viu1Wp7qaEBVtitKDf+ujNe+S2NH6Rv65XFW7w/TPBT21uzRcvfrv0/8t+0FxPRu/17tLI1S27X/3bDjj0p2q2Rui95bEa+mcXmofbdeQERW68v+cq6vtv1i14QubZry0oVU/D44MCQkJTq9nzpypWbNmNWtXV1en/Px83XXXXU7709LStHbtWrfOVVBQoLVr1+q+++5zO742Tex79+7Vzz//3PR68+bN+uqrrxQTE6NevXq1YWTm8c4L8XrnBdfX9D58e59m+85NOumwx1v6cE8tfbinT2IDfOHcCTt07oQdLt+75ZHmq9nPu3aHzrvWdfsDuvep0WtbP/NJfGg9vloVX1RU5DQVHBnZ/IZeklRWVia73a74eOefsfHx8SopcX2TrwN69uypnTt3qqGhQbNmzdLEiRPdjrNNE/u6det0+umnN72eOnWqJGnChAlasmRJG0UFAAhKPloV7+kaL8tBl2YYhtFs38Hy8vK0d+9effbZZ7rrrrvUt29fXX755W6dr00T+2mnnSYjQO7kAwCAJ2JjYxUaGtqsOi8tLW1WxR8sKSlJkjRkyBDt2LFDs2bNcjuxs3gOAGAKrb0qPiIiQsnJycrNzXXan5ubqxEjRrh9HMMwDrtA72AsngMAmIPDaNy86e+hqVOnavz48UpJSVFqaqoWL16swsJCTZo0SVLj/Vm2bdumZcuWSZKeeOIJ9erVSwMGDJDUeF37Qw89pFtuucXtc5LYAQDm0AZ3nktPT1d5ebnmzJmj4uJiDR48WCtXrlRiYuMjr4uLi52uaXc4HJo2bZo2b96ssLAwHX300XrggQd0ww03uH1OixHAk9yVlZWKjo7W6ZGXKszi3d3SgCPVq5s+busQAL+prHIoYcB2VVRU+O2mYwdyxYizZiss3Nri4zTU12jtv2f6NVZfoGIHAJiCRV5e7uazSPyLxA4AMAdvn6keIAPcrIoHACCIULEDAEyB57EDABBMeB47AAAINFTsAABTsBiGLF4sgPOmb2sisQMAzMHx2+ZN/wDAUDwAAEGEih0AYAoMxQMAEExMsiqexA4AMAfuPAcAAAINFTsAwBS48xwAAMGEoXgAABBoqNgBAKZgcTRu3vQPBCR2AIA5MBQPAAACDRU7AMAcuEENAADBwyy3lGUoHgCAIELFDgAwB5MsniOxAwDMwZB3z1QPjLxOYgcAmANz7AAAIOBQsQMAzMGQl3PsPovEr0jsAABzMMniOYbiAQAIIlTsAABzcEiyeNk/AJDYAQCmwKp4AAAQcKjYAQDmYJLFcyR2AIA5mCSxMxQPAEAQoWIHAJiDSSp2EjsAwBxMcrkbQ/EAAFM4cLmbN1tLZGdnKykpSVarVcnJycrLyztk29dff11nn322unTpIpvNptTUVL3//vsenY/EDgCAnyxfvlyZmZmaPn26CgoKNGrUKI0ePVqFhYUu269Zs0Znn322Vq5cqfz8fJ1++um68MILVVBQ4PY5LYYRIJMGLlRWVio6OlqnR16qMEt4W4cD+MWrmz5u6xAAv6mscihhwHZVVFTIZrP55xy/5YqzjvmbwkIjW3ycBnut/v3TIx7FOnz4cJ1wwgnKyclp2jdw4ECNHTtWWVlZbh1j0KBBSk9P14wZM9xqT8UOADAHh+H9psZfFH6/1dbWujxdXV2d8vPzlZaW5rQ/LS1Na9eudS9kh0NVVVWKiYlx+2OS2AEA8EBCQoKio6ObtkNV3mVlZbLb7YqPj3faHx8fr5KSErfO9fDDD6u6ulqXXnqp2/GxKh4AYA4+utytqKjIaSg+MvLww/sWi/NSfMMwmu1z5eWXX9asWbP05ptvKi4uzu0wSewAAJPwMrGrsa/NZnNrjj02NlahoaHNqvPS0tJmVfzBli9froyMDP3zn//UWWed5VGUDMUDAOAHERERSk5OVm5urtP+3NxcjRgx4pD9Xn75ZV199dV66aWXdP7553t8Xip2AIA5tMGd56ZOnarx48crJSVFqampWrx4sQoLCzVp0iRJ0rRp07Rt2zYtW7ZMUmNSv+qqq/Too4/q5JNPbqr2o6KiFB0d7dY5SewAAHNwGDownN7y/p5JT09XeXm55syZo+LiYg0ePFgrV65UYmKiJKm4uNjpmvZFixapoaFBN910k2666aam/RMmTNCSJUvcOieJHQAAP5o8ebImT57s8r2Dk/Xq1au9Ph+JHQBgDoajcfOmfwAgsQMAzIGnuwEAEETaYI69LXC5GwAAQYSKHQBgDgzFAwAQRAx5mdh9FolfMRQPAEAQoWIHAJgDQ/EAAAQRh0OSF9eiOwLjOnaG4gEACCJU7AAAc2AoHgCAIGKSxM5QPAAAQYSKHQBgDia5pSyJHQBgCobhkOHFE9q86duaSOwAAHMwDO+qbubYAQBAa6NiBwCYg+HlHHuAVOwkdgCAOTgcksWLefIAmWNnKB4AgCBCxQ4AMAeG4gEACB6GwyHDi6H4QLncjaF4AACCCBU7AMAcGIoHACCIOAzJEvyJnaF4AACCCBU7AMAcDEOSN9exB0bFTmIHAJiC4TBkeDEUb5DYAQA4ghgOeVexc7kbAABoZVTsAABTYCgeAIBgYpKh+IBO7Ad+e2ow6ts4EsB/KqsC44cJ0BJVexu/361RDTeo3qv70zQoMHJNQCf2qqoqSVJe3RttHAngPwkD2joCwP+qqqoUHR3tl2NHRESoa9eu+qRkpdfH6tq1qyIiInwQlf9YjECZNHDB4XBo+/bt6tChgywWS1uHYwqVlZVKSEhQUVGRbDZbW4cD+BTf79ZnGIaqqqrUvXt3hYT4bz13TU2N6urqvD5ORESErFarDyLyn4Cu2ENCQtSzZ8+2DsOUbDYbP/gQtPh+ty5/Veq/Z7Vaj/iE7Ctc7gYAQBAhsQMAEERI7PBIZGSkZs6cqcjIyLYOBfA5vt8IBgG9eA4AADijYgcAIIiQ2AEACCIkdgAAggiJHQCAIEJih9uys7OVlJQkq9Wq5ORk5eXltXVIgE+sWbNGF154obp37y6LxaIVK1a0dUhAi5HY4Zbly5crMzNT06dPV0FBgUaNGqXRo0ersLCwrUMDvFZdXa3jjz9ejz/+eFuHAniNy93gluHDh+uEE05QTk5O076BAwdq7NixysrKasPIAN+yWCx64403NHbs2LYOBWgRKnb8obq6OuXn5ystLc1pf1pamtauXdtGUQEAXCGx4w+VlZXJbrcrPj7eaX98fLxKSkraKCoAgCskdrjt4EfjGobB43IB4AhDYscfio2NVWhoaLPqvLS0tFkVDwBoWyR2/KGIiAglJycrNzfXaX9ubq5GjBjRRlEBAFwJa+sAEBimTp2q8ePHKyUlRampqVq8eLEKCws1adKktg4N8NrevXv1888/N73evHmzvvrqK8XExKhXr15tGBngOS53g9uys7P14IMPqri4WIMHD9YjjzyiU045pa3DAry2evVqnX766c32T5gwQUuWLGn9gAAvkNgBAAgizLEDABBESOwAAAQREjsAAEGExA4AQBAhsQMAEERI7AAABBESOwAAQYTEDgBAECGxA16aNWuWhg4d2vT66quv1tixY1s9jl9//VUWi0VfffXVIdv07t1bCxYscPuYS5YsUceOHb2OzWKxaMWKFV4fB8AfI7EjKF199dWyWCyyWCwKDw9Xnz59dNttt6m6utrv53700Ufdvg2pO8kYADzBQ2AQtM4991w999xzqq+vV15eniZOnKjq6mrl5OQ0a1tfX6/w8HCfnDc6OtonxwGAlqBiR9CKjIxU165dlZCQoHHjxumKK65oGg4+MHz+7LPPqk+fPoqMjJRhGKqoqND111+vuLg42Ww2nXHGGfr666+djvvAAw8oPj5eHTp0UEZGhmpqapzeP3go3uFwaN68eerbt68iIyPVq1cv3X///ZKkpKQkSdKwYcNksVh02mmnNfV77rnnNHDgQFmtVg0YMEDZ2dlO5/niiy80bNgwWa1WpaSkqKCgwON/o/nz52vIkCFq3769EhISNHnyZO3du7dZuxUrVqhfv36yWq06++yzVVRU5PT+22+/reTkZFmtVvXp00ezZ89WQ0ODx/EA8B6JHaYRFRWl+vr6ptc///yzXnnlFb322mtNQ+Hnn3++SkpKtHLlSuXn5+uEE07QmWeeqV27dkmSXnnlFc2cOVP333+/1q1bp27dujVLuAebNm2a5s2bp3vuuUfr16/XSy+9pPj4eEmNyVmS/v3vf6u4uFivv/66JOmpp57S9OnTdf/992vDhg2aO3eu7rnnHi1dulSSVF1drQsuuED9+/dXfn6+Zs2apdtuu83jf5OQkBAtXLhQ3333nZYuXaoPP/xQd9xxh1Obffv26f7779fSpUv16aefqrKyUpdddlnT+++//76uvPJKTZkyRevXr9eiRYu0ZMmSpl9eALQyAwhCEyZMMMaMGdP0+vPPPzc6d+5sXHrppYZhGMbMmTON8PBwo7S0tKnNBx98YNhsNqOmpsbpWEcffbSxaNEiwzAMIzU11Zg0aZLT+8OHDzeOP/54l+eurKw0IiMjjaeeesplnJs3bzYkGQUFBU77ExISjJdeeslp37333mukpqYahmEYixYtMmJiYozq6uqm93Nyclwe6/cSExONRx555JDvv/LKK0bnzp2bXj/33HOGJOOzzz5r2rdhwwZDkvH5558bhmEYo0aNMubOnet0nOeff97o1q1b02tJxhtvvHHI8wLwHebYEbTeeecdHXXUUWpoaFB9fb3GjBmjxx57rOn9xMREdenSpel1fn6+9u7dq86dOzsdZ//+/dq0aZMkacOGDZo0aZLT+6mpqfroo49cxrBhwwbV1tbqzDPPdDvunTt3qqioSBkZGbruuuua9jc0NDTN32/YsEHHH3+82rVr5xSHpz766CPNnTtX69evV2VlpRoaGlRTU6Pq6mq1b99ekhQWFqaUlJSmPgMGDFDHjh21YcMGnXTSScrPz9d///tfpwrdbrerpqZG+/btc4oRgP+R2BG0Tj/9dOXk5Cg8PFzdu3dvtjjuQOI6wOFwqFu3blq9enWzY7X0kq+oqCiP+zgcDkmNw/HDhw93ei80NFSSZBhGi+L5vS1btui8887TpEmTdO+99yomJkaffPKJMjIynKYspMbL1Q52YJ/D4dDs2bN18cUXN2tjtVq9jhOAZ0jsCFrt27dX37593W5/wgknqKSkRGFhYerdu7fLNgMHDtRnn32mq666qmnfZ599dshjHnPMMYqKitIHH3ygiRMnNns/IiJCUmOFe0B8fLx69OihX375RVdccYXL4x577LF6/vnntX///qZfHg4Xhyvr1q1TQ0ODHn74YYWENC63eeWVV5q1a2ho0Lp163TSSSdJkjZu3Kg9e/ZowIABkhr/3TZu3OjRvzUA/yGxA78566yzlJqaqrFjx2revHnq37+/tm/frpUrV2rs2LFKSUnRX//6V02YMEEpKSn605/+pBdffFHff/+9+vTp4/KYVqtVd955p+644w5FRERo5MiR2rlzp77//ntlZGQoLi5OUVFRWrVqlXr27Cmr1aro6GjNmjVLU6ZMkc1m0+jRo1VbW6t169Zp9+7dmjp1qsaNG6fp06crIyNDd999t3799Vc99NBDHn3eo48+Wg0NDXrsscd04YUX6tNPP9WTTz7ZrF14eLhuueUWLVy4UOHh4br55pt18sknNyX6GTNm6IILLlBCQoIuueQShYSE6JtvvtG3336r++67z/P/CABeYVU88BuLxaKVK1fqlFNO0bXXXqt+/frpsssu06+//tq0ij09PV0zZszQnXfeqeTkZG3ZskU33njjYY97zz336NZbb9WMGTM0cOBApaenq7S0VFLj/PXChQu1aNEide/eXWPGjJEkTZw4UU8//bSWLFmiIUOG6NRTT9WSJUuaLo876qij9Pbbb2v9+vUaNmyYpk+frnnz5nn0eYcOHar58+dr3rx5Gjx4sF588UVlZWU1a9euXTvdeeedGjdunFJTUxUVFaV//OMfTe+fc845euedd5Sbm6sTTzxRJ598subPn6/ExESP4gHgGxbDF5N1AADgiEDFDgBAECGxAwAQREjsAAAEERI7AABBhMQOAEAQIbEDABBESOwAAAQREjsAAEGExA4AQBAhsQMAEERI7AAABJH/D0rOC3sq8FEpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.87552"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.evaluate_model(best_model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5033f3-fa01-48d2-a061-08287ef785d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CSCE479 (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
